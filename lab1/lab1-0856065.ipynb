{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lab1-0856065.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPKcpMaa5jTuPXYsLWRVqah"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Z9HWrORPqdOY","colab_type":"text"},"source":["## Fetching the corpus"]},{"cell_type":"code","metadata":{"id":"koJQHSgnjrlw","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import math\n","import string\n","\n","def get_corpus():\n","  df = pd.read_csv(\"https://raw.githubusercontent.com/bshmueli/108-nlp/master/reuters.csv\")\n","  print(\"Dataset size\", len(df))\n","  print(\"Dataset columns\", df.columns)\n","  titles = df['title'].to_list() # remember to revert\n","  contents = df['content'].to_list()\n","  return titles, contents"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kYxahlJOki0r","colab_type":"code","colab":{}},"source":["def tokenize(document):\n","  words = document.split(' ')\n","  return words"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QNrRx_nJMbA4","colab_type":"text"},"source":["## Computing word frequencies"]},{"cell_type":"code","metadata":{"id":"gSawQxdcqwZf","colab_type":"code","colab":{}},"source":["from collections import Counter\n","\n","def get_vocab(corpus):\n","  vocabulary = Counter()\n","  for document in corpus:\n","    # Turn to lowercase\n","    d_lower = document.lower()\n","\n","    # Remove punctuation\n","    remove_punctuation_map = dict((ord(char), None) for char in (string.punctuation+\"”\"))\n","    no_punctuation = d_lower.translate(remove_punctuation_map)\n","    \n","    # Tokenize\n","    tokens = tokenize(no_punctuation)\n","    \n","    # Filter stopwords and numbers and remove \"\"\n","    sw = pd.read_csv(\"https://raw.githubusercontent.com/bshmueli/108-nlp/master/stopwords.txt\", header=None)\n","    sw = sw.values\n","    filtered = [w for w in tokens if (not w in sw) and (not w == \"\") and (not w.isdigit())]\n","    \n","    vocabulary.update(filtered)\n","  return vocabulary\n","\n","def get_doc_vocab(document):\n","  vocabulary = Counter()\n","  # Turn to lowercase\n","  d_lower = document.lower()\n","\n","  # Remove punctuation\n","  remove_punctuation_map = dict((ord(char), None) for char in (string.punctuation+\"”\"))\n","  no_punctuation = d_lower.translate(remove_punctuation_map)\n","    \n","  # Tokenize\n","  tokens = tokenize(no_punctuation)\n","    \n","  # Filter stopwords and numbers and remove \"\"\n","  sw = pd.read_csv(\"https://raw.githubusercontent.com/bshmueli/108-nlp/master/stopwords.txt\", header=None)\n","  sw = sw.values\n","  filtered = [w for w in tokens if (not w in sw) and (not w == \"\") and (not w.isdigit())]\n","    \n","  vocabulary.update(filtered)\n","  return vocabulary"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P1TsorJlMieT","colab_type":"text"},"source":["## Computing TFIDF vector"]},{"cell_type":"code","metadata":{"id":"KeffPoW2sgMC","colab_type":"code","colab":{}},"source":["def TF(word, doc_vocab): # the frequency of term x in document y\n","  return doc_vocab[word] / sum(doc_vocab.values())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YtxqtYi5tJ_-","colab_type":"code","colab":{}},"source":["def DF(word, vocab): # number of documents contains x\n","  return sum(1 for count in vocab if word in count)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gWdhFO6Pyur4","colab_type":"code","colab":{}},"source":["def IDF(word, vocab):\n","  return math.log(len(vocab) / DF(word, vocab))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3QY77JDqU_IX","colab_type":"code","colab":{}},"source":["def TFIDF(word, doc_vocab, vocab):\n","  return TF(word, doc_vocab) * IDF(word, vocab)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u5CV_YaPxl3i","colab_type":"code","colab":{}},"source":["def doc2vec(doc):\n","  doc_vocab = get_doc_vocab(doc)\n","  words = list(doc_vocab)\n","  return [TFIDF(token, doc_vocab, vocab) if token in words else 0 for token, freq in vocab]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JvhyGmqWAyfe","colab_type":"text"},"source":["## Computing the similarity between two documents"]},{"cell_type":"code","metadata":{"id":"EvB9z2oiV_N0","colab_type":"code","colab":{}},"source":["def cosine_similarity(vec_a, vec_b):\n","  assert len(vec_a) == len(vec_b)\n","  if sum(vec_a) == 0 or sum(vec_b) == 0:\n","    return 0 # hack\n","  a_b = sum(i[0] * i[1] for i in zip(vec_a, vec_b))\n","  a_2 = sum([i*i for i in vec_a])\n","  b_2 = sum([i*i for i in vec_b])\n","  return a_b/(math.sqrt(a_2) * math.sqrt(b_2))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jvUqanpLV_rb","colab_type":"code","colab":{}},"source":["def doc_similarity(doc_a, doc_b):\n","  return cosine_similarity(doc2vec(doc_a), doc2vec(doc_b))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oxJY5p3wMo4S","colab_type":"text"},"source":["## Find similar documents"]},{"cell_type":"code","metadata":{"id":"zDfHX7yauUyd","colab_type":"code","colab":{}},"source":["def k_similar(seed_id, k=5):\n","  seed_doc = corpus[seed_id]\n","  print('> \"{}\"'.format(titles[seed_id]))\n","\n","  similarities = [doc_similarity(seed_doc, doc) for doc in corpus]\n","  top_indices = sorted(range(len(similarities)), key=lambda i: similarities[i])[-k:]\n","  nearest = [[titles[id], similarities[id]] for id in top_indices]\n","  for story in reversed(nearest):\n","    print('* \"{}\" ({})'.format(story[0], story[1]))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_GHNAtjXMwoI","colab_type":"text"},"source":["## Test our program"]},{"cell_type":"code","metadata":{"id":"t-JPRkmHxUBp","colab_type":"code","outputId":"6f854ab3-958a-476f-c991-5b4eb43fe6fc","executionInfo":{"status":"ok","timestamp":1585499702669,"user_tz":-480,"elapsed":882978,"user":{"displayName":"Szyu Chen","photoUrl":"","userId":"09994010923073845328"}},"colab":{"base_uri":"https://localhost:8080/","height":176}},"source":["titles, corpus = get_corpus()\n","vocab = get_vocab(corpus).most_common(1000)\n","k_similar(856065%1000)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Dataset size 5354\n","Dataset columns Index(['title', 'content'], dtype='object')\n","> \"Brazil minister backs tariff to curb U.S. ethanol imports\"\n","* \"Brazil minister backs tariff to curb U.S. ethanol imports\" (1.0)\n","* \"U.S. Commerce’s Ross says 3 percent GDP growth not achievable this year\" (0.7616640839546344)\n","* \"Canada panel says dumping duties on U.S. drywall should be cut\" (0.7354920248674934)\n","* \"German business group fears trade war with U.S.\" (0.7128311737654646)\n","* \"Ahead of NAFTA talks, U.S. sets 20 percent duties on Canadian softwood lumber\" (0.711515269926266)\n"],"name":"stdout"}]}]}